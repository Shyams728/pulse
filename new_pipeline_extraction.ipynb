{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "def get_data_from_file(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        print(f'File not found: {file_path}')\n",
    "        return None\n",
    "\n",
    "def process_data(data_directory, engine):\n",
    "    quarter_data = []\n",
    "\n",
    "    for current_dir, subdirs, files in os.walk(data_directory):\n",
    "        if 'aggregated' in current_dir:\n",
    "            data_type = os.path.basename(os.path.dirname(os.path.dirname(current_dir)))\n",
    "            subfolder_name = os.path.basename(current_dir)\n",
    "\n",
    "            if 'state' in current_dir:\n",
    "                for state in os.listdir(current_dir):\n",
    "                    state_dir = os.path.join(current_dir, state)\n",
    "\n",
    "                    for file in os.listdir(state_dir):\n",
    "                        if file.endswith('.json'):\n",
    "                            file_path = os.path.join(state_dir, file)\n",
    "                            parsed_data = get_data_from_file(file_path)\n",
    "\n",
    "                            if parsed_data is not None:\n",
    "                                year = int(file_path.split('/')[-3])\n",
    "                                quarter = int(file.split('.')[0])\n",
    "                                extract_function = choose_appropriate_data_extraction_function(data_type, subfolder_name, state)\n",
    "                                extracted_data = extract_function(parsed_data, year, quarter)\n",
    "                                if extracted_data is not None:\n",
    "                                    quarter_data.append(extracted_data)\n",
    "            else:\n",
    "                for file in files:\n",
    "                    if file.endswith('.json'):\n",
    "                        file_path = os.path.join(current_dir, file)\n",
    "                        parsed_data = get_data_from_file(file_path)\n",
    "\n",
    "                        if parsed_data is not None:\n",
    "                            year = int(file_path.split('/')[-2])\n",
    "                            quarter = int(file.split('.')[0])\n",
    "                            extract_function = choose_appropriate_data_extraction_function(data_type, subfolder_name, None)\n",
    "                            extracted_data = extract_function(parsed_data, year, quarter)\n",
    "                            if extracted_data is not None:\n",
    "                                quarter_data.append(extracted_data)\n",
    "\n",
    "    if not quarter_data:\n",
    "        print(\"No data to process.\")\n",
    "        return None\n",
    "\n",
    "    df = pd.concat(quarter_data, ignore_index=True)\n",
    "    if df.empty:\n",
    "        print(\"No data to save to the database.\")\n",
    "        return None\n",
    "\n",
    "    file_name = choose_appropriate_data_extraction_function.__name__\n",
    "    try:\n",
    "        df.to_sql(f'{file_name}', engine, index=False, if_exists='replace')\n",
    "        engine.execute(f\"CREATE INDEX idx_quarter ON {file_name} (quarter)\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to save data to the database: {e}\")\n",
    "        return None\n",
    "\n",
    "    return df\n",
    "\n",
    "# Example of a data extraction function\n",
    "def extract_aggregated_insurance_country_data(parsed_data, year, quarter):\n",
    "    table = []\n",
    "    transaction_data = parsed_data['data']['transactionData']\n",
    "\n",
    "    for transaction in transaction_data:\n",
    "        row = {\n",
    "            'name': transaction['name'],\n",
    "            'count': transaction['paymentInstruments'][0]['count'],\n",
    "            'amount': transaction['paymentInstruments'][0]['amount'] \n",
    "        }\n",
    "        table.append(row)\n",
    "\n",
    "    return pd.DataFrame(table)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_aggregated_insurance_state_data(parsed_data, year, quarter,state):\n",
    "    table = []\n",
    "    transaction_data = parsed_data['data']['transactionData']\n",
    "\n",
    "    for transaction in transaction_data:\n",
    "        row = {\n",
    "            'state': state,\n",
    "            'year': year,\n",
    "            'quarter': quarter,\n",
    "            'type_of_transaction': transaction['name'],\n",
    "            'number_of_transactions': transaction['paymentInstruments'][0]['count'],\n",
    "            'total_amount': transaction['paymentInstruments'][0]['amount'],\n",
    "        }\n",
    "        table.append(row)\n",
    "\n",
    "    return pd.DataFrame(table)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 342)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m<tokenize>:342\u001b[0;36m\u001b[0m\n\u001b[0;31m    }\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "def get_data_from_file(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        print(f'File not found: {file_path}')\n",
    "        return None\n",
    "\n",
    "def process_data(data_directory, engine):\n",
    "    quarter_data = []\n",
    "\n",
    "    for current_dir, subdirs, files in os.walk(data_directory):\n",
    "        if 'aggregated' in current_dir or 'map' in current_dir or 'top' in current_dir:\n",
    "            data_type = os.path.basename(os.path.dirname(os.path.dirname(current_dir)))\n",
    "            subfolder_name = os.path.basename(current_dir)\n",
    "\n",
    "            if 'state' in current_dir:\n",
    "                for state in os.listdir(current_dir):\n",
    "                    state_dir = os.path.join(current_dir, state)\n",
    "\n",
    "                    for file in os.listdir(state_dir):\n",
    "                        if file.endswith('.json'):\n",
    "                            file_path = os.path.join(state_dir, file)\n",
    "                            parsed_data = get_data_from_file(file_path)\n",
    "\n",
    "                            if parsed_data is not None:\n",
    "                                year = int(file_path.split('/')[-3])\n",
    "                                quarter = int(file.split('.')[0])\n",
    "                                extract_function = choose_appropriate_data_extraction_function(data_type, subfolder_name, state)\n",
    "                                extracted_data = extract_function(parsed_data, year, quarter)\n",
    "                                if extracted_data is not None:\n",
    "                                    quarter_data.append(extracted_data)\n",
    "            else:\n",
    "                for file in files:\n",
    "                    if file.endswith('.json'):\n",
    "                        file_path = os.path.join(current_dir, file)\n",
    "                        parsed_data = get_data_from_file(file_path)\n",
    "\n",
    "                        if parsed_data is not None:\n",
    "                            year = int(file_path.split('/')[-2])\n",
    "                            quarter = int(file.split('.')[0])\n",
    "                            extract_function = choose_appropriate_data_extraction_function(data_type, subfolder_name, None)\n",
    "                            extracted_data = extract_function(parsed_data, year, quarter)\n",
    "                            if extracted_data is not None:\n",
    "                                quarter_data.append(extracted_data)\n",
    "\n",
    "    if not quarter_data:\n",
    "        print(\"No data to process.\")\n",
    "        return None\n",
    "\n",
    "    df = pd.concat(quarter_data, ignore_index=True)\n",
    "    if df.empty:\n",
    "        print(\"No data to save to the database.\")\n",
    "        return None\n",
    "\n",
    "    file_name = choose_appropriate_data_extraction_function.__name__\n",
    "    try:\n",
    "        df.to_sql(f'{file_name}', engine, index=False, if_exists='replace')\n",
    "        engine.execute(f\"CREATE INDEX idx_quarter ON {file_name} (quarter)\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to save data to the database: {e}\")\n",
    "        return None\n",
    "\n",
    "    return df\n",
    "\n",
    "# Define the data extraction functions here\n",
    "\n",
    "# Example of a data extraction function\n",
    "def extract_aggregated_insurance_country_data(parsed_data, year, quarter):\n",
    "    table = []\n",
    "    transaction_data = parsed_data['data']['transactionData']\n",
    "\n",
    "    for transaction in transaction_data:\n",
    "        row = {\n",
    "            'year': year,\n",
    "            'quarter': quarter,\n",
    "            'name': transaction['name'],\n",
    "            'count': transaction['paymentInstruments'][0]['count'],\n",
    "            'amount': transaction['paymentInstruments'][0]['amount']  # Assuming 'amount' is a key in the JSON\n",
    "        }\n",
    "        table.append(row)\n",
    "\n",
    "    return pd.DataFrame(table)\n",
    "\n",
    "# Define the other data extraction functions here\n",
    "def extract_aggregated_insurance_country_data(parsed_data):\n",
    "    table = []\n",
    "    transaction_data = parsed_data['data']['transactionData']\n",
    "\n",
    "    for transaction in transaction_data:\n",
    "        row = {\n",
    "            'year': int(os.path.basename(os.path.dirname(file_path))),\n",
    "            'quarter': int(file.split('.')[0]),\n",
    "            'name': transaction['name'],\n",
    "            'count': transaction['paymentInstruments'][0]['count'],\n",
    "            'amount': transaction['paymentInstruments'][0]['amount'],\n",
    "        }\n",
    "        table.append(row)\n",
    "\n",
    "    return pd.DataFrame(table)\n",
    "\n",
    "\n",
    "def extract_aggregated_insurance_state_data(parsed_data):\n",
    "    table = []\n",
    "    from_timestamp = parsed_data['data']['from']\n",
    "    to_timestamp = parsed_data['data']['to']\n",
    "    transaction_data = parsed_data['data']['transactionData']\n",
    "\n",
    "    for transaction in transaction_data:\n",
    "        row = {\n",
    "            'state': state.replace('-', ' ').title(),\n",
    "            'year': int(os.path.basename(os.path.dirname(file_path))),\n",
    "            'quarter': int(file.split('.')[0]),\n",
    "            'from_timestamp': from_timestamp,\n",
    "            'to_timestamp': to_timestamp,\n",
    "            'type_of_transaction': transaction['name'],\n",
    "            'number_of_transactions': transaction['paymentInstruments'][0]['count'],\n",
    "            'total_amount': transaction['paymentInstruments'][0]['amount'],\n",
    "        }\n",
    "        table.append(row)\n",
    "\n",
    "    return pd.DataFrame(table)\n",
    "\n",
    "\n",
    "def extract_aggregated_transaction_country_data(parsed_data):\n",
    "    table = []\n",
    "    transaction_data = parsed_data['data']['transactionData']\n",
    "\n",
    "    for transaction in transaction_data:\n",
    "        row = {\n",
    "            'year': int(os.path.basename(os.path.dirname(file_path))),\n",
    "            'quarter': int(file.split('.')[0]),\n",
    "            'name': transaction['name'],\n",
    "            'count': transaction['paymentInstruments'][0]['count'],\n",
    "            'amount': transaction['paymentInstruments'][0]['amount'],\n",
    "        }\n",
    "        table.append(row)\n",
    "\n",
    "    return pd.DataFrame(table)\n",
    "\n",
    "\n",
    "def extract_aggregated_transaction_state_data(parsed_data):\n",
    "    table = []\n",
    "    from_timestamp = parsed_data['data']['from']\n",
    "    to_timestamp = parsed_data['data']['to']\n",
    "    transaction_data = parsed_data['data']['transactionData']\n",
    "\n",
    "    for transaction in transaction_data:\n",
    "        row = {\n",
    "            'state': state.replace('-', ' ').title(),\n",
    "            'year': int(os.path.basename(os.path.dirname(file_path))),\n",
    "            'quarter': int(file.split('.')[0]),\n",
    "            'type_of_transaction': transaction['name'],\n",
    "            'number_of_transactions': transaction['paymentInstruments'][0]['count'],\n",
    "            'total_amount': transaction['paymentInstruments'][0]['amount'],\n",
    "        }\n",
    "        table.append(row)\n",
    "\n",
    "    return pd.DataFrame(table)\n",
    "\n",
    "\n",
    "def extract_aggregated_user_country_data(parsed_data):\n",
    "    table = []\n",
    "    registered_users = parsed_data[\"data\"][\"aggregated\"][\"registeredUsers\"]\n",
    "    total_open_apps = parsed_data[\"data\"][\"aggregated\"][\"appOpens\"]\n",
    "    users_by_device = parsed_data[\"data\"][\"usersByDevice\"]\n",
    "\n",
    "    if users_by_device is not None:\n",
    "        for user_device in users_by_device:\n",
    "            row = {\n",
    "                'year': int(os.path.basename(os.path.dirname(file_path))),\n",
    "                'quarter': int(file.split('.')[0]),\n",
    "                \"registered_users\": registered_users,\n",
    "                \"total_open_apps\": total_open_apps,\n",
    "                \"phone_brand\": user_device[\"brand\"],\n",
    "                \"phone_count\": user_device[\"count\"],\n",
    "                \"Percentage\": f\"{user_device['percentage'] * 100:.2f}\",\n",
    "            }\n",
    "            table.append(row)\n",
    "\n",
    "    return pd.DataFrame(table)\n",
    "\n",
    "\n",
    "def extract_aggregated_user_state_data(parsed_data):\n",
    "    table = []\n",
    "    registered_users = parsed_data[\"data\"][\"aggregated\"][\"registeredUsers\"]\n",
    "    total_open_apps = parsed_data[\"data\"][\"aggregated\"][\"appOpens\"]\n",
    "    users_by_device = parsed_data[\"data\"][\"usersByDevice\"]\n",
    "\n",
    "    if users_by_device is not None:\n",
    "        for user_device in users_by_device:\n",
    "            row = {\n",
    "                'state': state.replace('-', ' ').title(),\n",
    "                'year': int(os.path.basename(os.path.dirname(file_path))),\n",
    "                'quarter': int(file.split('.')[0]),\n",
    "                \"registered_users\": registered_users,\n",
    "                \"total_open_apps\": total_open_apps,\n",
    "                \"phone_brand\": user_device[\"brand\"],\n",
    "                \"phone_count\": user_device[\"count\"],\n",
    "                \"Percentage\": f\"{user_device['percentage'] * 100:.2f}\",\n",
    "            }\n",
    "            table.append(row)\n",
    "\n",
    "    return pd.DataFrame(table)\n",
    "\n",
    "\n",
    "def extract_map_insurance_hover_country_data(parsed_data):\n",
    "    table = []\n",
    "    hover_data_list = parsed_data[\"data\"][\"hoverDataList\"]\n",
    "\n",
    "    for entry in hover_data_list:\n",
    "        metric_data = entry[\"metric\"][0]\n",
    "        row = {\n",
    "            'year': int(os.path.basename(os.path.dirname(file_path))),\n",
    "            'quarter': int(file.split('.')[0]),\n",
    "            'state': entry[\"name\"].replace('-', ' ').title(),\n",
    "            'total_transactions_count': metric_data[\"count\"],\n",
    "            'total_transactions_amount': metric_data[\"amount\"],\n",
    "        }\n",
    "        table.append(row)\n",
    "\n",
    "    return pd.DataFrame(table)\n",
    "\n",
    "\n",
    "def extract_map_insurance_hover_state_data(parsed_data):\n",
    "    table = []\n",
    "    hover_data_list = parsed_data[\"data\"][\"hoverDataList\"]\n",
    "\n",
    "    for entry in hover_data_list:\n",
    "        district_name = entry[\"name\"].replace('-', ' ').title()),\n",
    "        metric_data = entry[\"metric\"][0]\n",
    "        total_transactions_count = metric_data[\"count\"]\n",
    "        total_transactions_amount = metric_data[\"amount\"]\n",
    "\n",
    "        row = {\n",
    "            'year': int(os.path.basename(os.path.dirname(file_path))),\n",
    "            'quarter': int(file.split('.')[0]),\n",
    "            'state': state.replace('-', ' ').title(),\n",
    "            'districts_name': district_name,\n",
    "            'total_transactions_count': total_transactions_count,\n",
    "            'total_transactions_amount': total_transactions_amount,\n",
    "        }\n",
    "        table.append(row)\n",
    "\n",
    "    return pd.DataFrame(table)\n",
    "\n",
    "\n",
    "def extract_map_transaction_hover_country_data(parsed_data):\n",
    "    table = []\n",
    "    hover_data_list = parsed_data[\"data\"][\"hoverDataList\"]\n",
    "\n",
    "    for entry in hover_data_list:\n",
    "        metric_data = entry[\"metric\"][0]\n",
    "        row = {\n",
    "            'year': int(os.path.basename(os.path.dirname(file_path))),\n",
    "            'quarter': int(file.split('.')[0]),\n",
    "            'state': entry[\"name\"].replace('-', ' ').title(),\n",
    "            'total_transactions_count': metric_data[\"count\"],\n",
    "            'total_transactions_amount': metric_data[\"amount\"],\n",
    "        }\n",
    "        table.append(row)\n",
    "\n",
    "    return pd.DataFrame(table)\n",
    "\n",
    "\n",
    "def extract_map_transaction_hover_state_data(parsed_data):\n",
    "    table = []\n",
    "    hover_data_list = parsed_data[\"data\"][\"hoverDataList\"]\n",
    "\n",
    "    for entry in hover_data_list:\n",
    "        district_name = entry[\"name\"]\n",
    "        metric_data = entry[\"metric\"][0]\n",
    "        total_transactions_count = metric_data[\"count\"]\n",
    "        total_transactions_amount = metric_data[\"amount\"]\n",
    "\n",
    "        row = {\n",
    "            'year': int(os.path.basename(os.path.dirname(file_path))),\n",
    "            'quarter': int(file.split('.')[0]),\n",
    "            'state': state.replace('-', ' ').title(),\n",
    "            'districts_name': district_name,\n",
    "            'total_transactions_count': total_transactions_count,\n",
    "            'total_transactions_amount': total_transactions_amount,\n",
    "        }\n",
    "        table.append(row)\n",
    "\n",
    "    return pd.DataFrame(table)\n",
    "\n",
    "\n",
    "def extract_map_user_hover_country_data(parsed_data):\n",
    "    table = []\n",
    "    hover_data = parsed_data[\"data\"][\"hoverData\"]\n",
    "\n",
    "    for state, state_data in hover_data.items():\n",
    "        row = {\n",
    "            'year': int(os.path.basename(os.path.dirname(file_path))),\n",
    "            'quarter': int(file.split('.')[0]),\n",
    "            'state': state.replace('-', ' ').title(),\n",
    "            'registered_users': state_data[\"registeredUsers\"],\n",
    "        }\n",
    "        table.append(row)\n",
    "\n",
    "    return pd.DataFrame(table)\n",
    "\n",
    "\n",
    "def extract_map_user_hover_state_data(parsed_data):\n",
    "    table = []\n",
    "    hover_data = parsed_data[\"data\"][\"hoverData\"]\n",
    "\n",
    "    for district, district_data in hover_data.items():\n",
    "        row = {\n",
    "            'year': int(os.path.basename(os.path.dirname(file_path))),\n",
    "            'quarter': int(file.split('.')[0]),\n",
    "            'state': state.replace('-', ' ').title(),\n",
    "            'districts_name': district,\n",
    "            'registered_users': district_data[\"registeredUsers\"],\n",
    "        }\n",
    "        table.append(row)\n",
    "\n",
    "    return pd.DataFrame(table)\n",
    "\n",
    "\n",
    "def extract_top_insurance_country_data(parsed_data):\n",
    "    entity_data = []\n",
    "    for entity_type in ['states', 'districts', 'pincodes']:\n",
    "        entities = parsed_data['data'][entity_type]\n",
    "\n",
    "        for entity in entities:\n",
    "            entity_row = {\n",
    "                'year': int(os.path.basename(os.path.dirname(file_path))),\n",
    "                'quarter': int(file.split('.')[0]),\n",
    "                'entity_type': entity_type,\n",
    "                'entity_name': entity['entityName'],\n",
    "                'transaction_type': entity['metric']['type'],\n",
    "                'count': entity['metric']['count'],\n",
    "                'amount': entity['metric']['amount'],\n",
    "            }\n",
    "            entity_data.append(entity_row)\n",
    "\n",
    "    return pd.DataFrame(entity_data)\n",
    "\n",
    "\n",
    "def extract_top_insurance_state_data(parsed_data):\n",
    "    for entity_type in ['states', 'districts', 'pincodes']:\n",
    "        entities = parsed_data['data'].get(entity_type)\n",
    "\n",
    "        if entities is not None:\n",
    "            entity_data = []\n",
    "\n",
    "            for entity in entities:\n",
    "                entity_name = entity[\"entityName\"]\n",
    "                entity_metric = entity[\"metric\"]\n",
    "\n",
    "                row = {\n",
    "                    'year': int(os.path.basename(os.path.dirname(file_path))),\n",
    "                    'quarter': int(file.split('.')[0]),\n",
    "                    'entity_type': entity_type,\n",
    "                    'entity_name': entity_name,\n",
    "                    'transaction_type': entity_metric['type'],\n",
    "                    'count': entity_metric['count'],\n",
    "                    'amount': entity_metric['amount'],\n",
    "                }\n",
    "                entity_data.append(row)\n",
    "\n",
    "            return pd.DataFrame(entity_data)\n",
    "\n",
    "# Function to choose appropriate data extraction function\n",
    "def choose_appropriate_data_extraction_function(data_type, subfolder_name, state):\n",
    "    if data_type == 'aggregated':\n",
    "        if subfolder_name == 'insurance':\n",
    "            if state is not None:\n",
    "                return extract_aggregated_insurance_state_data\n",
    "            else:\n",
    "                return extract_aggregated_insurance_country_data\n",
    "        elif subfolder_name == 'user':\n",
    "            if state is not None:\n",
    "                return extract_aggregated_user_state_data\n",
    "            else:\n",
    "                return extract_aggregated_user_country_data\n",
    "        elif subfolder_name == 'transaction':\n",
    "            if state is not None:\n",
    "                return extract_aggregated_transaction_state_data\n",
    "            else:\n",
    "                return extract_aggregated_transaction_country_data\n",
    "    elif data_type == 'map':\n",
    "        if subfolder_name == 'insurance':\n",
    "            if state is not None:\n",
    "                return extract_map_insurance_hover_state_data\n",
    "            else:\n",
    "                return extract_map_insurance_hover_country_data\n",
    "        elif subfolder_name == 'transaction':\n",
    "            if state is not None:\n",
    "                return extract_map_transaction_hover_state_data\n",
    "            else:\n",
    "                return extract_map_transaction_hover_country_data\n",
    "        elif subfolder_name == 'user':\n",
    "            if state is not None:\n",
    "                return extract_map_user_hover_state_data\n",
    "            else:\n",
    "                return extract_map_user_hover_country_data\n",
    "    elif data_type == 'top':\n",
    "        if subfolder_name == 'insurance':\n",
    "            if state is not None:\n",
    "                return extract_top_insurance_state_data\n",
    "            else:\n",
    "                return extract_top_insurance_country_data\n",
    "\n",
    "# Database connection\n",
    "engine = create_engine('sqlite:///mydatabase.db')\n",
    "\n",
    "# Example usage\n",
    "data_directory = '/home/user/pulse/data'\n",
    "df = process_data(data_directory, engine)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
